{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ade1443b",
   "metadata": {},
   "source": [
    "### <b>Telecommunication Assistant - B2C </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bffdf11",
   "metadata": {},
   "source": [
    "Importing relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fcef1a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import os\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import faiss\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2743ed23",
   "metadata": {},
   "source": [
    "Getting the API key from environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44492973",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Telecom Assistant\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"HUGGINGFACE_API_KEY\"] = os.getenv(\"HUGGINGFACE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a073939",
   "metadata": {},
   "source": [
    "LLM Model - From Groq (Deepseek-r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58019688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Chennai is the capital city of the Indian state of Tamil Nadu. It is a major cultural, economic, and educational center in South India. Chennai is known for its rich cultural heritage, including traditional Tamil arts, music, and dance. The city is also home to several historical landmarks, such as the Kapaleeshwarar Temple and Fort St. George, which reflect its colonial past.\n",
      "\n",
      "Chennai is a hub for the automobile industry, earning it the nickname \"Detroit of India.\" It is also a significant center for information technology and healthcare. The city is well-connected by air, land, and sea, with the Chennai International Airport and the Chennai Port being key infrastructure.\n",
      "\n",
      "Chennai's cuisine is a blend of traditional Tamil dishes and modern fusion food. The city is famous for its filter coffee, idli, dosa, and other South Indian delicacies. Chennai also hosts several cultural festivals throughout the year, including the Margazhi festival, which showcases classical music and dance performances.\n",
      "\n",
      "The city faces challenges such as urbanization, traffic congestion, and environmental issues, but it continues to grow and develop, maintaining its status as one of India's most vibrant cities.\n"
     ]
    }
   ],
   "source": [
    "model = ChatGroq(temperature=0, model_name=\"deepseek-r1-distill-llama-70b\", streaming=True)\n",
    "print(model.invoke(\"Chennai\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "022936e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bharath.sr.lv\\AppData\\Local\\Temp\\ipykernel_18804\\3273188620.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_kwargs = {\"device\" : \"cpu\"})\n",
      "c:\\Users\\bharath.sr.lv\\Desktop\\ConversationalAI\\Telecom_Assistant_POC\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={'device': 'cpu'}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vector Embeddings (Embedding Model Output features : 384)\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_kwargs = {\"device\" : \"cpu\"})\n",
    "embedding_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d23216",
   "metadata": {},
   "source": [
    "Loading the FAISS Vector Indices from local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadd9cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Local\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore import InMemoryDocstore\n",
    "\n",
    "local_vector_db = FAISS.load_local(\".telecomusecase_FAISS_DB\",\n",
    "                                    embeddings=embedding_model,\n",
    "                                    allow_dangerous_deserialization=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
